{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import IPython.display as ipd\n",
    "from argparse import Namespace\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import argparse\n",
    "import scipy\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import comet_ml\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from glob2 import glob\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import copy \n",
    "import IPython\n",
    "import numpy as np\n",
    "from asteroid.losses import pairwise_neg_sisdr\n",
    "from asteroid.losses import pairwise_neg_snr\n",
    "import BaseLine.DatasetLoaders.Chime as Chime\n",
    "import BaseLine.Utils.MixtureConsistency as MixtureConsistency\n",
    "import BaseLine.Models.ImprovedSudormrf as ImprovedSudormrf\n",
    "import BaseLine.Metrics.DNNMosMetric as DNNMosMetric\n",
    "import pickle\n",
    "sys.path.append(\"../\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \",\".join([\"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sample_rate = 16000\n",
    "timelength = 4.\n",
    "fixed_n_sources = 1\n",
    "get_only_active_speakers = False\n",
    "split = 'dev'\n",
    "random_order = True\n",
    "n_samples = 250\n",
    "time_samples = int (sample_rate * timelength)\n",
    "data_loader = Chime.Dataset(\n",
    "    sample_rate = sample_rate, \n",
    "    fixed_n_sources = fixed_n_sources, \n",
    "    timelength = timelength, \n",
    "    augment = random_order,\n",
    "    zero_pad = True, \n",
    "    split = split, \n",
    "    get_only_active_speakers = get_only_active_speakers, \n",
    "    normalize_audio = False, \n",
    "    n_samples = n_samples\n",
    ")\n",
    "eval_chime_gen = data_loader.get_generator(batch_size=batch_size, num_workers=1) \n",
    "def get_new_student(hparams, depth_growth):\n",
    "    student = ImprovedSudormrf.SuDORMRF(\n",
    "        out_channels = hparams[\"out_channels\"], \n",
    "        in_channels = hparams[\"in_channels\"], \n",
    "        num_blocks = int(depth_growth * hparams[\"num_blocks\"]), \n",
    "        upsampling_depth = hparams[\"upsampling_depth\"],\n",
    "        enc_kernel_size = hparams[\"enc_kernel_size\"], \n",
    "        enc_num_basis = hparams[\"enc_num_basis\"], \n",
    "        num_sources = 2,\n",
    "    )\n",
    "    return student\n",
    "hparams = {\n",
    "    'out_channels': 512,\n",
    "    'in_channels': 512,\n",
    "    'num_blocks': 8,\n",
    "    'upsampling_depth': 7,\n",
    "    'enc_kernel_size': 41,\n",
    "    'enc_num_basis': 512,\n",
    "}\n",
    "wo_mix_con_chkpt = \"/home/thymios/projects/unsup_speech_enh_adaptation/pretrained_checkpoints/libri1to3_sup_teacher.pt\"\n",
    "wo_mix_con_model = get_new_student(hparams, depth_growth=1)\n",
    "wo_mix_con_model.load_state_dict(torch.load(wo_mix_con_chkpt))\n",
    "wo_mix_con_model = wo_mix_con_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_mix_con_model.eval()\n",
    "for cnt, mixture in enumerate(eval_chime_gen):\n",
    "    input_mix = mixture.unsqueeze(1).cuda()\n",
    "    input_mix_std = input_mix.std(-1, keepdim = True)\n",
    "    input_mix_mean = input_mix.mean(-1, keepdim = True)\n",
    "    input_mix = (input_mix - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "    with torch.no_grad():\n",
    "        rec_sources_wavs = wo_mix_con_model(input_mix)\n",
    "        new_mix = rec_sources_wavs[:, 0:1] + rec_sources_wavs[:, 1:]\n",
    "        new_mix_std = new_mix.std(-1, keepdim = True)\n",
    "        new_mix_mean = new_mix.mean(-1, keepdim = True)\n",
    "        rec_sources_wavs = (rec_sources_wavs - new_mix_mean) / (new_mix_std + 1e-9)\n",
    "        teacher_est_active_speakers = rec_sources_wavs[:, 0:1].detach().cpu()\n",
    "        teacher_est_noises = rec_sources_wavs[:, 1:].detach().cpu()\n",
    "    #Play the mixture and the estimated sources\n",
    "    mix, est_s, est_n = input_mix[0, 0].cpu().numpy(), teacher_est_active_speakers[0, 0].cpu().numpy(), teacher_est_noises[0, 0].cpu().numpy()\n",
    "    print(\"Initial Mixture\")\n",
    "    ipd.display(ipd.Audio(input_mix[0:, 0].cpu().numpy(), rate = 16000))\n",
    "    print(\"Estimated Teacher Speech\")\n",
    "    ipd.display(ipd.Audio(teacher_est_active_speakers[0:, 0].detach().numpy(), rate = 16000))\n",
    "    print(\"Teacher Estimated Noise\")\n",
    "    ipd.display(ipd.Audio(teacher_est_noises[0:, 0].detach().numpy(), rate = 16000))\n",
    "    #Plot the mixture and the estimated sources\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (15,5), sharey = True)\n",
    "    ax[0].plot(mix, label = \"mixture\")\n",
    "    ax[1].plot(est_s, label = \"est speaker mix\")\n",
    "    ax[2].plot(est_n, label = \"est noise\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    #MEasure the DNSMOS\n",
    "    dnsmos_val = DNNMosMetric.compute_dnsmos(est_s, fs = 16000)\n",
    "    print(dnsmos_val)\n",
    "    if cnt > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract proper numbers for val and test for DNS-MOS\n",
    "eval_res_dic = {'sig_mos': [], 'bak_mos': [], 'ovr_mos': []}\n",
    "wo_mix_con_model.eval()\n",
    "for cnt, mixture in tqdm(enumerate(eval_chime_gen)):\n",
    "    input_mix = mixture.unsqueeze(1).cuda()\n",
    "    input_mix_std = input_mix.std(-1, keepdim = True)\n",
    "    input_mix_mean = input_mix.mean(-1, keepdim = True)\n",
    "    input_mix = (input_mix - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "    with torch.no_grad():\n",
    "        rec_sources_wavs = wo_mix_con_model(input_mix)\n",
    "        new_mix = rec_sources_wavs[:, 0:1] + rec_sources_wavs[:, 1:]\n",
    "        new_mix_std = new_mix.std(-1, keepdim = True)\n",
    "        new_mix_mean = new_mix.mean(-1, keepdim = True)\n",
    "        rec_sources_wavs = (rec_sources_wavs - new_mix_mean) / (new_mix_std + 1e-9)\n",
    "        teacher_est_active_speakers = rec_sources_wavs[:, 0:1].detach().cpu()\n",
    "        teacher_est_noises = rec_sources_wavs[:, 1:].detach().cpu()\n",
    "    mix, est_s, est_n = input_mix[0, 0].cpu().numpy(), teacher_est_active_speakers[0, 0].cpu()\n",
    "    #MEasure the DNSMOS\n",
    "    dnsmos_val = DNNMosMetric.compute_dnsmos(est_s, fs=16000)\n",
    "    for k, v in dnsmos_val.items():\n",
    "        eval_res_dic[k].append(v)\n",
    "    if cnt > 250:\n",
    "        break\n",
    "val_res_dic = {'sig_mos': [], 'bak_mos': [], 'ovr_mos': []}\n",
    "wo_mix_con_model.eval()\n",
    "for cnt, mixture in tqdm(enumerate(val_chime_gen)):\n",
    "    input_mix = mixture.unsqueeze(1).cuda()\n",
    "    input_mix_std = input_mix.std(-1, keepdim = True)\n",
    "    input_mix_mean = input_mix.mean(-1, keepdim = True)\n",
    "    input_mix = (input_mix - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "    with torch.no_grad():\n",
    "        rec_sources_wavs = wo_mix_con_model(input_mix)\n",
    "        new_mix = rec_sources_wavs[:, 0:1] + rec_sources_wavs[:, 1:]\n",
    "        new_mix_std = new_mix.std(-1, keepdim = True)\n",
    "        new_mix_mean = new_mix.mean(-1, keepdim = True)\n",
    "        rec_sources_wavs = (rec_sources_wavs - new_mix_mean) / (new_mix_std + 1e-9)\n",
    "        teacher_est_active_speakers = rec_sources_wavs[:, 0:1].detach().cpu()\n",
    "        teacher_est_noises = rec_sources_wavs[:, 1:].detach().cpu()\n",
    "        mix, est_s, est_n = input_mix[0, 0].cpu().numpy(), teacher_est_active_speakers[0, 0].cpu().numpy(), teacher_est_noises[0, 0].cpu().numpy()\n",
    "    #MEasure the DNSMOS\n",
    "    dnsmos_val = DNNMosMetric.compute_dnsmos(est_s, fs=16000)\n",
    "    for k, v in dnsmos_val.items():\n",
    "        val_res_dic[k].append(v)\n",
    "    if cnt > 250:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, this_dic in [('val', val_res_dic), ('eval', eval_res_dic)]:\n",
    "    print(name)\n",
    "    for k, v in this_dic.items():\n",
    "        print(k, np.median(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sample_rate = 16000\n",
    "timelength = 4.\n",
    "fixed_n_sources = 1\n",
    "get_only_active_speakers = False\n",
    "split = 'train'\n",
    "random_order = False\n",
    "n_samples = -1\n",
    "time_samples = int(sample_rate * timelength)\n",
    "data_loader = Chime.Dataset( \n",
    "    sample_rate = sample_rate, \n",
    "    fixed_n_sources = fixed_n_sources, \n",
    "    timelength = timelength, \n",
    "    augment = random_order,\n",
    "    zero_pad = True, \n",
    "    split = split, \n",
    "    get_only_active_speakers = get_only_active_speakers, \n",
    "    normalize_audio = False, \n",
    "    n_samples = n_samples\n",
    ")\n",
    "train_chime_gen = data_loader.get_generator(batch_size = batch_size, num_workers = 1) \n",
    "for i in range(2):\n",
    "    initial_seed = 11\n",
    "    torch.manual_seed(initial_seed + i)\n",
    "    np.random.seed(initial_seed + i)\n",
    "    wo_mix_con_model.eval()\n",
    "    for cnt, mixture in enumerate(train_chime_gen):\n",
    "        input_mix = mixture.unsqueeze(1).cuda()\n",
    "        input_mix_std = input_mix.std(-1, keepdim = True)\n",
    "        input_mix_mean = input_mix.mean(-1, keepdim = True)\n",
    "        input_mix = (input_mix - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "        with torch.no_grad():\n",
    "            rec_sources_wavs = wo_mix_con_model(input_mix)\n",
    "            new_mix = rec_sources_wavs[:, 0:1] + rec_sources_wavs[:, 1:]\n",
    "            new_mix_std = new_mix.std(-1, keepdim = True)\n",
    "            new_mix_mean = new_mix.mean(-1, keepdim = True)\n",
    "            rec_sources_wavs = (rec_sources_wavs - new_mix_mean) / (new_mix_std + 1e-9)\n",
    "            teacher_est_active_speakers = rec_sources_wavs[:, 0:1].detach().cpu()\n",
    "            teacher_est_noises = rec_sources_wavs[:, 1:].detach().cpu()\n",
    "        #Play the mixture and the estimated sources\n",
    "        mix, est_s, est_n = input_mix[0, 0].cpu().numpy(), teacher_est_active_speakers[0, 0].cpu().numpy(), teacher_est_noises[0, 0].cpu().numpy()\n",
    "        print(\"Initial Mixture\")\n",
    "        ipd.display(ipd.Audio(input_mix[0:, 0].cpu().numpy(), rate = 16000))\n",
    "        print(\"Estimated Teacher Speech\")\n",
    "        ipd.display(ipd.Audio(teacher_est_active_speakers[0:, 0].detach().numpy(), rate=16000))\n",
    "        print(\"Teacher Estimated Noise\")\n",
    "        ipd.display(ipd.Audio(teacher_est_noises[0:, 0].detach().numpy(), rate = 16000))\n",
    "        #Plot the mixture and the estimated sources\n",
    "        fig, ax = plt.subplots(1, 3, figsize = (15,5), sharey = True)\n",
    "        ax[0].plot(mix, label=\"mixture\")\n",
    "        ax[1].plot(est_s, label=\"est speaker mix\")\n",
    "        ax[2].plot(est_n, label=\"est noise\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        #MEasure the DNSMOS\n",
    "        dnsmos_val = DNNMosMetric.compute_dnsmos(est_s, fs = 16000)\n",
    "        print(dnsmos_val)\n",
    "        if cnt > -1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test a model with mixture consistency\n",
    "batch_size = 1\n",
    "sample_rate = 16000\n",
    "timelength = 4.\n",
    "fixed_n_sources = 1\n",
    "get_only_active_speakers = False\n",
    "split = 'dev'\n",
    "random_order = False\n",
    "n_samples = 250\n",
    "time_samples = int(sample_rate * timelength)\n",
    "data_loader = Chime.Dataset(\n",
    "    sample_rate = sample_rate, \n",
    "    fixed_n_sources = fixed_n_sources, \n",
    "    timelength = timelength, \n",
    "    augment = random_order,\n",
    "    zero_pad = True, \n",
    "    split = split, \n",
    "    get_only_active_speakers = get_only_active_speakers, \n",
    "    normalize_audio = False, \n",
    "    n_samples = n_samples\n",
    ")\n",
    "val_chime_gen = data_loader.get_generator(batch_size = batch_size, num_workers=1) \n",
    "data_loader = Chime.Dataset(\n",
    "    sample_rate = sample_rate, \n",
    "    fixed_n_sources = fixed_n_sources, \n",
    "    timelength = timelength, augment = random_order,\n",
    "    zero_pad=True, split='eval', \n",
    "    get_only_active_speakers=get_only_active_speakers, \n",
    "    normalize_audio=False, \n",
    "    n_samples = n_samples\n",
    ")\n",
    "eval_chime_gen = data_loader.get_generator(batch_size=batch_size, num_workers=1) \n",
    "def get_new_student(hparams, depth_growth):\n",
    "    student = ImprovedSudormrf.SuDORMRF(\n",
    "        out_channels = hparams[\"out_channels\"], \n",
    "        in_channels = hparams[\"in_channels\"], \n",
    "        num_blocks = int(depth_growth * hparams[\"num_blocks\"]), \n",
    "        upsampling_depth = hparams[\"upsampling_depth\"], \n",
    "        enc_kernel_size = hparams[\"enc_kernel_size\"], \n",
    "        enc_num_basis = hparams[\"enc_num_basis\"], \n",
    "        num_sources =2,\n",
    "    )\n",
    "    return student\n",
    "hparams = {\n",
    "    'out_channels': 512,\n",
    "    'in_channels': 512,\n",
    "    'num_blocks': 8,\n",
    "    'upsampling_depth': 7,\n",
    "    'enc_kernel_size': 41,\n",
    "    'enc_num_basis': 512,\n",
    "}\n",
    "w_mix_con_chkpt = \"/mnt/data/thymios_backup/thymios/UCHIME_checkpoints/ublock8_sup_teacher_libri1to3mix_0.5single_w_mixcon/sup_teacher_epoch_100.pt\"\n",
    "w_mix_con_model = get_new_student(hparams, depth_growth=1)\n",
    "w_mix_con_model.load_state_dict(torch.load(w_mix_con_chkpt))\n",
    "w_mix_con_model = w_mix_con_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract proper numbers for val and test for DNS-MOS\n",
    "eval_res_dic = {'sig_mos': [], 'bak_mos': [], 'ovr_mos': []}\n",
    "w_mix_con_model.eval()\n",
    "for cnt, mixture in tqdm(enumerate(eval_chime_gen)):\n",
    "    input_mix = mixture.unsqueeze(1).cuda()\n",
    "    input_mix_std = input_mix.std(-1, keepdim=True)\n",
    "    input_mix_mean = input_mix.mean(-1, keepdim=True)\n",
    "    input_mix = (input_mix - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "    with torch.no_grad():\n",
    "        rec_sources_wavs = w_mix_con_model(input_mix)\n",
    "        rec_sources_wavs = MixtureConsistency.apply(rec_sources_wavs, input_mix)\n",
    "        new_mix = rec_sources_wavs[:, 0:1] + rec_sources_wavs[:, 1:]\n",
    "        new_mix_std = new_mix.std(-1, keepdim=True)\n",
    "        new_mix_mean = new_mix.mean(-1, keepdim=True)\n",
    "        rec_sources_wavs = (rec_sources_wavs - new_mix_mean) / (new_mix_std + 1e-9)\n",
    "        teacher_est_active_speakers = rec_sources_wavs[:, 0:1].detach().cpu()\n",
    "        teacher_est_noises = rec_sources_wavs[:, 1:].detach().cpu()\n",
    "    mix, est_s, est_n = input_mix[0, 0].cpu().numpy(), teacher_est_active_speakers[0, 0].cpu().numpy(), teacher_est_noises[0, 0].cpu().numpy()\n",
    "    #MEasure the DNSMOS\n",
    "    dnsmos_val = DNNMosMetric.compute_dnsmos(mix, fs=16000)\n",
    "    for k, v in dnsmos_val.items():\n",
    "        eval_res_dic[k].append(v)\n",
    "    if cnt > 250:\n",
    "        break\n",
    "val_res_dic = {'sig_mos': [], 'bak_mos': [], 'ovr_mos': []}\n",
    "wo_mix_con_model.eval()\n",
    "for cnt, mixture in tqdm(enumerate(val_chime_gen)):\n",
    "    input_mix = mixture.unsqueeze(1).cuda()\n",
    "    input_mix_std = input_mix.std(-1, keepdim = True)\n",
    "    input_mix_mean = input_mix.mean(-1, keepdim = True)\n",
    "    input_mix = (input_mix - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "    with torch.no_grad():\n",
    "        rec_sources_wavs = w_mix_con_model(input_mix)\n",
    "        rec_sources_wavs = MixtureConsistency.apply(rec_sources_wavs, input_mix)\n",
    "        new_mix = rec_sources_wavs[:, 0:1] + rec_sources_wavs[:, 1:]\n",
    "        new_mix_std = new_mix.std(-1, keepdim = True)\n",
    "        new_mix_mean = new_mix.mean(-1, keepdim = True)\n",
    "        rec_sources_wavs = (rec_sources_wavs - new_mix_mean) / (new_mix_std + 1e-9)\n",
    "        teacher_est_active_speakers = rec_sources_wavs[:, 0:1].detach().cpu()\n",
    "        teacher_est_noises = rec_sources_wavs[:, 1:].detach().cpu()\n",
    "    mix, est_s, est_n = input_mix[0, 0].cpu().numpy(), teacher_est_active_speakers[0, 0].cpu().numpy(), teacher_est_noises[0, 0].cpu().numpy()\n",
    "    # MEasure the DNSMOS\n",
    "    dnsmos_val = DNNMosMetric.compute_dnsmos(mix, fs=16000)\n",
    "    for k, v in dnsmos_val.items():\n",
    "        val_res_dic[k].append(v)\n",
    "    \n",
    "    if cnt > 250:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, this_dic in [('val', val_res_dic), ('eval', eval_res_dic)]:\n",
    "    print(name)\n",
    "    for k, v in this_dic.items():\n",
    "        print(k, np.median(v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
